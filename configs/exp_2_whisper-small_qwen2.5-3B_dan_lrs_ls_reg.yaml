# =============================================================================
# Experiment 1: Danish Baseline (Train from Scratch)
# SLAM-ASR with Whisper-small + Qwen2.5-3B on Danish ~5h
# =============================================================================

model:
  model_name: ASRLLM
  file: models/model.py:ASRLLM
  
  # LLM - Qwen2.5-3B (frozen)
  llm_model: Qwen/Qwen2.5-3B
  llm_model_name: qwen2.5-3B
  llm_dim: 2048
  llm_model_path: null
  llm_type: decoder_only
  
  # Encoder - Whisper-small (frozen)
  encoder_model: small
  encoder_model_name: whisper-small
  encoder_dim: 768
  encoder_ds_rate: 2
  encoder_model_path: null
  encoder_num_layers: null  # Use all 12 layers
  encoder_type: finetune
  
  # Projector - train from scratch (architecture matches English for comparison)
  projector: linear
  projector_ds_rate: 3
  projector_hidden_dim: 2048
  projector_dropout: 0.2  # Increased from 0.1 for regularization
  projector_path: null  # No pretrained weights
  
  modal: audio
  normalize: false

train:
  model_name: ASRLLM
  run_validation: true
  
  # Batch settings
  batch_size: 32
  val_batch_size: 8
  gradient_accumulation_steps: 2
  num_workers: 4
  max_eval_batches: 100
  max_new_tokens: 128
  
  # Generation
  repetition_penalty: 1.5
  
  # Training
  num_epochs: 100
  total_steps: 50000
  warmup_steps: 500
  validation_interval: 225  # ~1 epoch (3592/16)
  
  # Optimizer (fixed)
  lr: 5.0e-5              # Increased from 2e-5
  weight_decay: 0.01      # Reduced from 0.1
  grad_clip: 1.0
  gamma: 0.85
  label_smoothing: 0.1  # Regularization to prevent overconfidence
  
  # Memory
  mixed_precision: true
  use_fp16: false
  quantization: false
  
  # Freeze encoder and LLM
  freeze_llm: true
  freeze_encoder: true
  freeze_layers: false
  num_freeze_layers: 0
  
  # Output
  output_dir: outputs/exp_1_dan_base/
  save_model: true
  seed: 42
  one_gpu: true
  use_peft: false
  use_fast_kernels: false
  batching_strategy: packing
  context_length: 384

scheduler:
  name: cosine_with_warmup
  total_training_steps: 50000
  warmup_steps: 500
  min_lr_ratio: 0.1  # Final LR = initial_lr * 0.1 = 2e-6

early_stopping:
  monitor: val/wer
  mode: min
  patience: 15
  min_delta: 0.005

data:
  dataset: speech_dataset
  file: datamodule/dataset.py:get_speech_dataset
  
  # Danish Common Voice
  train_data_path: data/common_voice_da/train.jsonl
  val_data_path: data/common_voice_da/validation.jsonl
  test_data_path: data/common_voice_da/test.jsonl
  
  # Audio
  input_type: mel
  mel_size: 80
  normalize: false
  projector_ds_rate: 3
  use_variable_length: true
  max_audio_length: 20
  fix_length_audio: -1
  
  # Text
  max_target_chars: 500
  inference_mode: false

log:
  use_wandb: true
  wandb_dir: ./wandb
  wandb_entity_name: null
  wandb_project_name: SLAM_ASR_Danish
  wandb_exp_name: exp_2_whisper-small_qwen2.5-3B_dan_lrs_ls_reg
  log_dir: ./logs
  log_filename: exp_1_dan_base.log
  log_interval: 50
