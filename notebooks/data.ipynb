{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "221a35df",
   "metadata": {},
   "source": [
    "### Common Voice 22.0 Dataset Preparation\n",
    "\n",
    "This notebook downloads, preprocesses, and saves the Common Voice dataset in HuggingFace Dataset format.\n",
    "\n",
    "**Dataset:** `fsicoli/common_voice_22_0`  \n",
    "**Languages:** Danish (da), English (en), Dutch (nl)\n",
    "\n",
    "**Preprocessing:**\n",
    "- Filter by duration: min 0.5s, max 30s\n",
    "- Lowercase transcription\n",
    "- Remove punctuation\n",
    "- Save both `raw_transcription` and `transcription` (preprocessed)\n",
    "\n",
    "**Output:** HuggingFace Dataset with pre-computed audio arrays (no need to reload from disk during training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f31f2ab",
   "metadata": {},
   "source": [
    "#### Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43d967f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "p:\\Programming\\Efficient_ASR_LLM\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import tarfile\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import csv\n",
    "\n",
    "from huggingface_hub import hf_hub_download, list_repo_files\n",
    "from datasets import Dataset, Audio, Features, Value\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c081b480",
   "metadata": {},
   "source": [
    "#### Step 2: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3b10928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: fsicoli/common_voice_22_0\n",
      "Language: da\n",
      "Output: ..\\data\\cv22_hf\n",
      "Duration filter: [0.5s, 30.0s]\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "DATASET_REPO = \"fsicoli/common_voice_22_0\"\n",
    "LANGUAGE = \"da\"  # Danish. Change to \"en\" for English, \"nl\" for Dutch\n",
    "SPLITS = [\"train\", \"dev\", \"test\"]  # dev will be renamed to validation\n",
    "OUTPUT_DIR = Path(\"../data/cv22_hf\")\n",
    "SAMPLE_RATE = 16000\n",
    "\n",
    "# Filtering\n",
    "MIN_DURATION = 0.5   # seconds - filter out very short/corrupted samples\n",
    "MAX_DURATION = 30.0  # seconds - Whisper's maximum input length\n",
    "\n",
    "print(f\"Dataset: {DATASET_REPO}\")\n",
    "print(f\"Language: {LANGUAGE}\")\n",
    "print(f\"Output: {OUTPUT_DIR}\")\n",
    "print(f\"Duration filter: [{MIN_DURATION}s, {MAX_DURATION}s]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb81b24b",
   "metadata": {},
   "source": [
    "#### Step 3: Define Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c90f0497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing examples:\n",
      "  'Hej, hvordan har du det?' -> 'hej hvordan har du det'\n",
      "  'Det er en god dag!' -> 'det er en god dag'\n",
      "  'Don't stop the music.' -> 'don't stop the music'\n",
      "  'Prijs: €50,00 (incl. BTW)' -> 'prijs 50 00 incl btw'\n"
     ]
    }
   ],
   "source": [
    "def preprocess_transcription(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Preprocess transcription:\n",
    "    - Convert to lowercase\n",
    "    - Remove all punctuation\n",
    "    - Collapse multiple spaces\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation (keep apostrophes for contractions like \"don't\")\n",
    "    text = re.sub(r\"[^\\w\\s']\", \" \", text)\n",
    "    \n",
    "    # Remove standalone apostrophes\n",
    "    text = re.sub(r\"(?<!\\w)'|'(?!\\w)\", \" \", text)\n",
    "    \n",
    "    # Collapse multiple spaces and strip\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Test the preprocessing\n",
    "test_examples = [\n",
    "    \"Hej, hvordan har du det?\",\n",
    "    \"Det er en god dag!\",\n",
    "    \"Don't stop the music.\",\n",
    "    \"Prijs: €50,00 (incl. BTW)\",\n",
    "]\n",
    "\n",
    "print(\"Preprocessing examples:\")\n",
    "for ex in test_examples:\n",
    "    print(f\"  '{ex}' -> '{preprocess_transcription(ex)}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acb236f",
   "metadata": {},
   "source": [
    "#### Step 4: Download Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "106eae2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download functions defined!\n"
     ]
    }
   ],
   "source": [
    "def download_transcript(language: str, split: str) -> list:\n",
    "    \"\"\"Download and parse transcript TSV file.\"\"\"\n",
    "    filename = f\"transcript/{language}/{split}.tsv\"\n",
    "    print(f\"Downloading: {filename}\")\n",
    "    \n",
    "    tsv_path = hf_hub_download(\n",
    "        repo_id=DATASET_REPO,\n",
    "        filename=filename,\n",
    "        repo_type=\"dataset\",\n",
    "    )\n",
    "    \n",
    "    samples = []\n",
    "    with open(tsv_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f, delimiter=\"\\t\")\n",
    "        for row in reader:\n",
    "            samples.append(dict(row))\n",
    "    \n",
    "    print(f\"  Loaded {len(samples)} transcript entries\")\n",
    "    return samples\n",
    "\n",
    "\n",
    "def download_and_extract_audio(language: str, split: str, output_dir: Path) -> Path:\n",
    "    \"\"\"Download and extract audio tar file.\"\"\"\n",
    "    # Audio format: audio/{lang}/{split}/{lang}_{split}_0.tar\n",
    "    filename = f\"audio/{language}/{split}/{language}_{split}_0.tar\"\n",
    "    print(f\"Downloading: {filename}\")\n",
    "    \n",
    "    tar_path = hf_hub_download(\n",
    "        repo_id=DATASET_REPO,\n",
    "        filename=filename,\n",
    "        repo_type=\"dataset\",\n",
    "    )\n",
    "    \n",
    "    # Extract\n",
    "    audio_dir = output_dir / \"audio\" / split\n",
    "    audio_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    print(f\"  Extracting to: {audio_dir}\")\n",
    "    with tarfile.open(tar_path, \"r\") as tar:\n",
    "        for member in tqdm(tar.getmembers(), desc=\"Extracting\"):\n",
    "            if member.isfile():\n",
    "                member.name = os.path.basename(member.name)\n",
    "                tar.extract(member, path=audio_dir)\n",
    "    \n",
    "    return audio_dir\n",
    "\n",
    "print(\"Download functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c174bb06",
   "metadata": {},
   "source": [
    "#### Step 5: Process and Create HuggingFace Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2883557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process function defined!\n"
     ]
    }
   ],
   "source": [
    "def process_split(language: str, split: str, output_dir: Path) -> Dataset:\n",
    "    \"\"\"\n",
    "    Download, preprocess, and create HuggingFace Dataset for a split.\n",
    "    \n",
    "    Returns Dataset with columns:\n",
    "    - audio: Dict with 'array' (numpy float32) and 'sampling_rate' (16000)\n",
    "    - raw_transcription: Original transcription\n",
    "    - transcription: Preprocessed transcription (lowercase, no punctuation)\n",
    "    - duration: Audio duration in seconds\n",
    "    - speaker_id: Client ID (anonymized)\n",
    "    \"\"\"\n",
    "    # Download transcript and audio\n",
    "    transcript = download_transcript(language, split)\n",
    "    audio_dir = download_and_extract_audio(language, split, output_dir)\n",
    "    \n",
    "    # Process samples - load audio arrays directly (no need for Audio feature decoding)\n",
    "    processed_samples = []\n",
    "    stats = {\"total\": 0, \"valid\": 0, \"too_short\": 0, \"too_long\": 0, \"missing\": 0, \"empty\": 0}\n",
    "    \n",
    "    print(f\"\\nProcessing {len(transcript)} samples...\")\n",
    "    \n",
    "    for sample in tqdm(transcript, desc=f\"Processing {split}\"):\n",
    "        stats[\"total\"] += 1\n",
    "        \n",
    "        # Get audio file path\n",
    "        audio_filename = sample.get(\"path\", \"\")\n",
    "        if not audio_filename:\n",
    "            stats[\"missing\"] += 1\n",
    "            continue\n",
    "            \n",
    "        audio_path = audio_dir / audio_filename\n",
    "        if not audio_path.exists():\n",
    "            stats[\"missing\"] += 1\n",
    "            continue\n",
    "        \n",
    "        # Get transcription\n",
    "        raw_text = sample.get(\"sentence\", \"\").strip()\n",
    "        if not raw_text:\n",
    "            stats[\"empty\"] += 1\n",
    "            continue\n",
    "        \n",
    "        # Load audio and get duration\n",
    "        try:\n",
    "            audio_array, sr = sf.read(str(audio_path))\n",
    "            duration = len(audio_array) / sr\n",
    "        except Exception as e:\n",
    "            stats[\"missing\"] += 1\n",
    "            continue\n",
    "        \n",
    "        # Filter by duration\n",
    "        if duration < MIN_DURATION:\n",
    "            stats[\"too_short\"] += 1\n",
    "            continue\n",
    "        if duration > MAX_DURATION:\n",
    "            stats[\"too_long\"] += 1\n",
    "            continue\n",
    "        \n",
    "        # Resample if needed (MP3 files from Common Voice are usually 48kHz)\n",
    "        if sr != SAMPLE_RATE:\n",
    "            import librosa\n",
    "            audio_array = librosa.resample(audio_array, orig_sr=sr, target_sr=SAMPLE_RATE)\n",
    "        \n",
    "        # Preprocess transcription\n",
    "        preprocessed_text = preprocess_transcription(raw_text)\n",
    "        \n",
    "        # Store audio array directly - no decoding needed during training!\n",
    "        processed_samples.append({\n",
    "            \"audio_array\": audio_array.astype(np.float32),  # Store array directly\n",
    "            \"sampling_rate\": SAMPLE_RATE,\n",
    "            \"raw_transcription\": raw_text,\n",
    "            \"transcription\": preprocessed_text,\n",
    "            \"duration\": round(duration, 3),\n",
    "            \"speaker_id\": sample.get(\"client_id\", \"\")[:16],\n",
    "        })\n",
    "        stats[\"valid\"] += 1\n",
    "    \n",
    "    # Print stats\n",
    "    print(f\"\\nStats for {split}:\")\n",
    "    print(f\"  Total: {stats['total']}\")\n",
    "    print(f\"  Valid: {stats['valid']}\")\n",
    "    print(f\"  Too short (<{MIN_DURATION}s): {stats['too_short']}\")\n",
    "    print(f\"  Too long (>{MAX_DURATION}s): {stats['too_long']}\")\n",
    "    print(f\"  Missing/Error: {stats['missing']}\")\n",
    "    print(f\"  Empty text: {stats['empty']}\")\n",
    "    \n",
    "    # Create HuggingFace Dataset - audio arrays are stored directly, no decoding needed\n",
    "    dataset = Dataset.from_list(processed_samples)\n",
    "    \n",
    "    total_hours = sum(s[\"duration\"] for s in processed_samples) / 3600\n",
    "    print(f\"  Total duration: {total_hours:.2f} hours\")\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "print(\"Process function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b549eb",
   "metadata": {},
   "source": [
    "#### Step 6: Download and Process Danish Dataset\n",
    "\n",
    "This will:\n",
    "1. Download transcript TSV files\n",
    "2. Download and extract audio tar files\n",
    "3. Load audio arrays, filter by duration, preprocess transcriptions\n",
    "4. Create HuggingFace Dataset objects\n",
    "\n",
    "**Note:** First run may take 10-30 minutes depending on your internet speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50017fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Processing: train\n",
      "============================================================\n",
      "Downloading: transcript/da/train.tsv\n",
      "  Loaded 3592 transcript entries\n",
      "Downloading: audio/da/train/da_train_0.tar\n",
      "  Extracting to: ..\\data\\cv22_hf\\audio\\train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting: 100%|██████████| 3603/3603 [00:19<00:00, 182.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 3592 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train: 100%|██████████| 3592/3592 [00:21<00:00, 168.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats for train:\n",
      "  Total: 3592\n",
      "  Valid: 3592\n",
      "  Too short (<0.5s): 0\n",
      "  Too long (>30.0s): 0\n",
      "  Missing/Error: 0\n",
      "  Empty text: 0\n",
      "  Total duration: 4.18 hours\n",
      "\n",
      "============================================================\n",
      "Processing: dev\n",
      "============================================================\n",
      "Downloading: transcript/da/dev.tsv\n",
      "  Loaded 2511 transcript entries\n",
      "Downloading: audio/da/dev/da_dev_0.tar\n",
      "  Extracting to: ..\\data\\cv22_hf\\audio\\dev\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting: 100%|██████████| 2631/2631 [00:16<00:00, 160.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 2511 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dev: 100%|██████████| 2511/2511 [00:14<00:00, 173.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats for dev:\n",
      "  Total: 2511\n",
      "  Valid: 2511\n",
      "  Too short (<0.5s): 0\n",
      "  Too long (>30.0s): 0\n",
      "  Missing/Error: 0\n",
      "  Empty text: 0\n",
      "  Total duration: 3.21 hours\n",
      "\n",
      "============================================================\n",
      "Processing: test\n",
      "============================================================\n",
      "Downloading: transcript/da/test.tsv\n",
      "  Loaded 2684 transcript entries\n",
      "Downloading: audio/da/test/da_test_0.tar\n",
      "  Extracting to: ..\\data\\cv22_hf\\audio\\test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting: 100%|██████████| 2759/2759 [00:16<00:00, 163.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 2684 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test: 100%|██████████| 2684/2684 [00:16<00:00, 163.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats for test:\n",
      "  Total: 2684\n",
      "  Valid: 2684\n",
      "  Too short (<0.5s): 0\n",
      "  Too long (>30.0s): 0\n",
      "  Missing/Error: 0\n",
      "  Empty text: 0\n",
      "  Total duration: 3.45 hours\n",
      "\n",
      "============================================================\n",
      "All splits processed!\n",
      "============================================================\n",
      "  train: 3592 samples\n",
      "  validation: 2511 samples\n",
      "  test: 2684 samples\n"
     ]
    }
   ],
   "source": [
    "# Create output directory\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Process each split\n",
    "datasets_dict = {}\n",
    "\n",
    "for split in SPLITS:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing: {split}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    dataset = process_split(LANGUAGE, split, OUTPUT_DIR)\n",
    "    \n",
    "    # Rename 'dev' to 'validation' for consistency\n",
    "    split_name = \"validation\" if split == \"dev\" else split\n",
    "    datasets_dict[split_name] = dataset\n",
    "    \n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"All splits processed!\")\n",
    "print('='*60)\n",
    "for name, ds in datasets_dict.items():\n",
    "    print(f\"  {name}: {len(ds)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032b1985",
   "metadata": {},
   "source": [
    "## Step 7: Inspect the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba5f02a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset features:\n",
      "{'audio_array': List(Value('float32')), 'sampling_rate': Value('int64'), 'raw_transcription': Value('string'), 'transcription': Value('string'), 'duration': Value('float64'), 'speaker_id': Value('string')}\n",
      "\n",
      "Sample examples from train set:\n",
      "\n",
      "Example 1:\n",
      "  Duration: 2.81s\n",
      "  Raw:      'Min fortræffelige lille nattergal!'\n",
      "  Cleaned:  'min fortræffelige lille nattergal'\n",
      "  Audio array shape: (44928,)\n",
      "  Sample rate: 16000\n",
      "\n",
      "Example 2:\n",
      "  Duration: 2.88s\n",
      "  Raw:      'Jeg venter grumme meget af den'\n",
      "  Cleaned:  'jeg venter grumme meget af den'\n",
      "  Audio array shape: (46080,)\n",
      "  Sample rate: 16000\n",
      "\n",
      "Example 3:\n",
      "  Duration: 4.25s\n",
      "  Raw:      'Men hendes vilje var fast, som hendes tillid til vorherre'\n",
      "  Cleaned:  'men hendes vilje var fast som hendes tillid til vorherre'\n",
      "  Audio array shape: (67968,)\n",
      "  Sample rate: 16000\n"
     ]
    }
   ],
   "source": [
    "# Look at the dataset structure\n",
    "print(\"Dataset features:\")\n",
    "print(datasets_dict[\"train\"].features)\n",
    "print()\n",
    "\n",
    "# Look at a few examples\n",
    "print(\"Sample examples from train set:\")\n",
    "for i in range(3):\n",
    "    sample = datasets_dict[\"train\"][i]\n",
    "    audio = np.array(sample['audio_array'])  # Convert list back to numpy array\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(f\"  Duration: {sample['duration']:.2f}s\")\n",
    "    print(f\"  Raw:      '{sample['raw_transcription']}'\")\n",
    "    print(f\"  Cleaned:  '{sample['transcription']}'\")\n",
    "    print(f\"  Audio array shape: {audio.shape}\")\n",
    "    print(f\"  Sample rate: {sample['sampling_rate']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaced325",
   "metadata": {},
   "source": [
    "## Step 8: Save as HuggingFace Dataset\n",
    "\n",
    "This saves the dataset in Arrow format, which:\n",
    "- Stores audio arrays directly (no need to reload from MP3 files)\n",
    "- Fast loading during training\n",
    "- Memory-mapped for efficient access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b588e2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving dataset to: ..\\data\\cv22_hf\\da\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (2/2 shards): 100%|██████████| 3592/3592 [00:01<00:00, 3069.75 examples/s]\n",
      "Saving the dataset (2/2 shards): 100%|██████████| 2511/2511 [00:00<00:00, 2788.24 examples/s]\n",
      "Saving the dataset (2/2 shards): 100%|██████████| 2684/2684 [00:00<00:00, 2763.94 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset saved successfully!\n",
      "Location: p:\\Programming\\Efficient_ASR_LLM\\notebooks\\..\\data\\cv22_hf\\da\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "# Create DatasetDict\n",
    "dataset_dict = DatasetDict(datasets_dict)\n",
    "\n",
    "# Save to disk\n",
    "save_path = OUTPUT_DIR / LANGUAGE\n",
    "print(f\"Saving dataset to: {save_path}\")\n",
    "\n",
    "dataset_dict.save_to_disk(str(save_path))\n",
    "\n",
    "print(f\"\\nDataset saved successfully!\")\n",
    "print(f\"Location: {save_path.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93525161",
   "metadata": {},
   "source": [
    "## Step 9: Load the Saved Dataset\n",
    "\n",
    "This demonstrates how to load the dataset during training - audio arrays are already pre-computed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a13d8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['audio_array', 'sampling_rate', 'raw_transcription', 'transcription', 'duration', 'speaker_id'],\n",
      "        num_rows: 3592\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['audio_array', 'sampling_rate', 'raw_transcription', 'transcription', 'duration', 'speaker_id'],\n",
      "        num_rows: 2511\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['audio_array', 'sampling_rate', 'raw_transcription', 'transcription', 'duration', 'speaker_id'],\n",
      "        num_rows: 2684\n",
      "    })\n",
      "})\n",
      "\n",
      "Sample from loaded dataset:\n",
      "  Duration: 2.81s\n",
      "  Raw transcription: 'Min fortræffelige lille nattergal!'\n",
      "  Transcription: 'min fortræffelige lille nattergal'\n",
      "  Audio array shape: (44928,)\n",
      "  Audio sample rate: 16000\n"
     ]
    }
   ],
   "source": [
    "# Load the saved dataset\n",
    "from datasets import load_from_disk\n",
    "\n",
    "load_path = OUTPUT_DIR / LANGUAGE\n",
    "loaded_dataset = load_from_disk(str(load_path))\n",
    "\n",
    "print(\"Loaded dataset:\")\n",
    "print(loaded_dataset)\n",
    "print()\n",
    "\n",
    "# Verify a sample\n",
    "sample = loaded_dataset[\"train\"][0]\n",
    "audio = np.array(sample['audio_array'])  # Convert list to numpy array\n",
    "print(\"Sample from loaded dataset:\")\n",
    "print(f\"  Duration: {sample['duration']:.2f}s\")\n",
    "print(f\"  Raw transcription: '{sample['raw_transcription']}'\")\n",
    "print(f\"  Transcription: '{sample['transcription']}'\")\n",
    "print(f\"  Audio array shape: {audio.shape}\")\n",
    "print(f\"  Audio sample rate: {sample['sampling_rate']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fa9149",
   "metadata": {},
   "source": [
    "## Step 10: Usage Example for Training\n",
    "\n",
    "Here's how to use the dataset in your training code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71a8078d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch contents:\n",
      "  Audio shape: torch.Size([4, 106560])\n",
      "  Transcriptions: ['vær opmærksom på at midlerne til kultur hovedsageligt er rettet mod de store bycentre', 'det var for flasken som om den levede det om igen', 'jo jeg tror jeg tror sagde han velsignede hr', 'vær så god hr']\n",
      "  Durations: [6.66, 4.608, 5.58, 1.908]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Example: Create a simple collate function\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Simple collate function for DataLoader.\"\"\"\n",
    "    audio_arrays = [torch.tensor(item[\"audio_array\"]) for item in batch]\n",
    "    transcriptions = [item[\"transcription\"] for item in batch]\n",
    "    durations = [item[\"duration\"] for item in batch]\n",
    "    \n",
    "    # Pad audio to same length\n",
    "    max_len = max(a.shape[0] for a in audio_arrays)\n",
    "    padded_audio = torch.zeros(len(audio_arrays), max_len)\n",
    "    for i, a in enumerate(audio_arrays):\n",
    "        padded_audio[i, :a.shape[0]] = a\n",
    "    \n",
    "    return {\n",
    "        \"audio\": padded_audio,\n",
    "        \"transcription\": transcriptions,\n",
    "        \"duration\": durations,\n",
    "    }\n",
    "\n",
    "# Create DataLoader\n",
    "train_loader = DataLoader(\n",
    "    loaded_dataset[\"train\"],\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "\n",
    "# Test loading a batch\n",
    "batch = next(iter(train_loader))\n",
    "print(\"Batch contents:\")\n",
    "print(f\"  Audio shape: {batch['audio'].shape}\")\n",
    "print(f\"  Transcriptions: {batch['transcription']}\")\n",
    "print(f\"  Durations: {batch['duration']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea0f417",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The dataset is now saved in HuggingFace format with:\n",
    "\n",
    "| Column | Description |\n",
    "|--------|-------------|\n",
    "| `audio_array` | Pre-computed audio as numpy float32 array |\n",
    "| `sampling_rate` | Audio sample rate (16000) |\n",
    "| `raw_transcription` | Original transcription (with punctuation and casing) |\n",
    "| `transcription` | Preprocessed transcription (lowercase, no punctuation) |\n",
    "| `duration` | Audio duration in seconds |\n",
    "| `speaker_id` | Anonymized speaker ID |\n",
    "\n",
    "**Benefits:**\n",
    "- ✅ Audio arrays are pre-computed and stored (no MP3 decoding during training)\n",
    "- ✅ Fast loading with memory-mapped Arrow files\n",
    "- ✅ Both raw and preprocessed transcriptions available\n",
    "- ✅ Duration filtering already applied\n",
    "- ✅ No FFmpeg dependency needed during training\n",
    "\n",
    "**To load in your training code:**\n",
    "```python\n",
    "from datasets import load_from_disk\n",
    "dataset = load_from_disk(\"data/cv22_hf/da\")\n",
    "train_data = dataset[\"train\"]\n",
    "\n",
    "# Access audio directly\n",
    "audio = train_data[0][\"audio_array\"]  # numpy array, ready to use!\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
